{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_424_Deploy_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "nteract": {
      "version": "0.22.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGGrt9EYlCqY"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Train Practice\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 4*\n",
        "\n",
        "Continue to use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. Apply regularization techniques to your model. \n",
        "\n",
        "*Don't forgot to switch to GPU on Colab!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptJ2b3wk62Ud"
      },
      "source": [
        "## Regularization\n",
        "\n",
        "Using your best performing model from the previous module, apply each of the following regularization strategies: \n",
        "* Early Stopping\n",
        "* Dropout\n",
        "* Weight Decay\n",
        "* Weight Constraint\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USXjs7Hk71Hy"
      },
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.layers import Dense, ReLU, Dropout\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTKa0Dw8hG-2",
        "outputId": "d4468a50-c30a-449f-c955-47462b88a673"
      },
      "source": [
        "def split_zip_df(path):\n",
        "  data = np.load(path)\n",
        "  features = 'arr_0'\n",
        "  target = 'arr_1'\n",
        "  X = data[features]\n",
        "  y = data[target]\n",
        "  X_train, X_test, y_train, y_test = train_test_split(\n",
        "      X, y, test_size=0.20,\n",
        "      stratify= y,\n",
        "      random_state=17)\n",
        "  X_train, X_val, y_train, y_val = train_test_split(\n",
        "      X_train, y_train, test_size=0.20,\n",
        "      stratify= y_train,\n",
        "      random_state=17)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "  \n",
        "X_train, y_train, X_val, y_val, X_test, y_test = split_zip_df('quickdraw10.npz')\n",
        "\n",
        "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((64000, 784), (64000,), (16000, 784), (16000,), (20000, 784), (20000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5Dt-jKPatIo",
        "outputId": "7ae9f015-c14f-4dd6-a5a6-9359a2d9f0bf"
      },
      "source": [
        "tf.random.set_seed(17)\n",
        "logdir = os.path.join(\"logs\", \"EarlyStopping-Loss\")\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5)\n",
        "\n",
        "# Normal values tend to be 0 to 0.01 on log scale\n",
        "wd = 0.001\n",
        "model = tf.keras.Sequential([\n",
        "    Dense(128, activation='relu', input_dim= 784, kernel_regularizer=regularizers.L2(wd)),\n",
        "    Dense(128, activation='relu', kernel_regularizer=regularizers.L2(wd)),\n",
        "    Dense(128, activation='relu', kernel_regularizer=regularizers.L2(wd)),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=72, \n",
        "          validation_data=(X_test,y_test),\n",
        "          callbacks=[tensorboard_callback, stop])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/72\n",
            "   2/2000 [..............................] - ETA: 51s - loss: 64.8305 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0059s vs `on_train_batch_end` time: 0.0449s). Check your callbacks.\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 2.0140 - accuracy: 0.6793 - val_loss: 1.1241 - val_accuracy: 0.7703\n",
            "Epoch 2/72\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 1.0134 - accuracy: 0.7952 - val_loss: 0.9213 - val_accuracy: 0.8055\n",
            "Epoch 3/72\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.8304 - accuracy: 0.8183 - val_loss: 0.7895 - val_accuracy: 0.8203\n",
            "Epoch 4/72\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.7176 - accuracy: 0.8316 - val_loss: 0.6909 - val_accuracy: 0.8296\n",
            "Epoch 5/72\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.6555 - accuracy: 0.8412 - val_loss: 0.6610 - val_accuracy: 0.8346\n",
            "Epoch 6/72\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.6263 - accuracy: 0.8468 - val_loss: 0.6589 - val_accuracy: 0.8409\n",
            "Epoch 7/72\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.6116 - accuracy: 0.8515 - val_loss: 0.6385 - val_accuracy: 0.8416\n",
            "Epoch 8/72\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.6009 - accuracy: 0.8535 - val_loss: 0.6419 - val_accuracy: 0.8396\n",
            "Epoch 9/72\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5875 - accuracy: 0.8583 - val_loss: 0.6520 - val_accuracy: 0.8417\n",
            "Epoch 10/72\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5827 - accuracy: 0.8594 - val_loss: 0.6315 - val_accuracy: 0.8473\n",
            "Epoch 11/72\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5778 - accuracy: 0.8610 - val_loss: 0.6483 - val_accuracy: 0.8393\n",
            "Epoch 12/72\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5703 - accuracy: 0.8627 - val_loss: 0.6297 - val_accuracy: 0.8462\n",
            "Epoch 13/72\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5681 - accuracy: 0.8654 - val_loss: 0.6187 - val_accuracy: 0.8490\n",
            "Epoch 14/72\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5622 - accuracy: 0.8650 - val_loss: 0.6291 - val_accuracy: 0.8504\n",
            "Epoch 15/72\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5588 - accuracy: 0.8668 - val_loss: 0.6386 - val_accuracy: 0.8462\n",
            "Epoch 16/72\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5555 - accuracy: 0.8679 - val_loss: 0.6299 - val_accuracy: 0.8468\n",
            "Epoch 17/72\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5539 - accuracy: 0.8688 - val_loss: 0.6361 - val_accuracy: 0.8494\n",
            "Epoch 18/72\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5522 - accuracy: 0.8694 - val_loss: 0.6322 - val_accuracy: 0.8511\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb19ce93ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pScpa3nRRxCN"
      },
      "source": [
        "## Deploy\n",
        "\n",
        "Save your model's weights using the Checkpoint function. Try reloading the model and making inference on your validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3HdCBDMnyI6",
        "outputId": "03407b84-5591-4860-8b22-c11c0671d57c"
      },
      "source": [
        "stop = EarlyStopping(monitor='val_accuracy', min_delta=0.005, patience=5)\n",
        "mcp = ModelCheckpoint('best_weights.h5', \n",
        "                      monitor='val_accuracy', \n",
        "                      verbose=1, \n",
        "                      save_best_only=True,\n",
        "                      save_weights_only=True)\n",
        "\n",
        "def get_model(dropout_rate):\n",
        "  model = tf.keras.Sequential([\n",
        "      Dense(128, activation='relu', input_dim= 784, kernel_constraint=MaxNorm(3)),\n",
        "      Dropout(dropout_rate),\n",
        "      Dense(128, activation='relu', kernel_constraint=MaxNorm(3)),\n",
        "      Dropout(dropout_rate),\n",
        "      Dense(128, activation='relu', kernel_constraint=MaxNorm(3)),\n",
        "      Dropout(dropout_rate),\n",
        "      Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(loss='sparse_categorical_crossentropy', \n",
        "                optimizer='adam', \n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model2 = get_model(0.2)\n",
        "model.fit(X_train, y_train, \n",
        "          epochs=100, \n",
        "          validation_data=(X_test,y_test),\n",
        "          callbacks=[stop, mcp])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.5525 - accuracy: 0.8686\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.84850, saving model to best_weights.h5\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5524 - accuracy: 0.8687 - val_loss: 0.6274 - val_accuracy: 0.8485\n",
            "Epoch 2/100\n",
            "1984/2000 [============================>.] - ETA: 0s - loss: 0.5463 - accuracy: 0.8708\n",
            "Epoch 00002: val_accuracy did not improve from 0.84850\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5471 - accuracy: 0.8706 - val_loss: 0.6272 - val_accuracy: 0.8465\n",
            "Epoch 3/100\n",
            "1982/2000 [============================>.] - ETA: 0s - loss: 0.5452 - accuracy: 0.8723\n",
            "Epoch 00003: val_accuracy improved from 0.84850 to 0.85335, saving model to best_weights.h5\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5456 - accuracy: 0.8724 - val_loss: 0.6138 - val_accuracy: 0.8533\n",
            "Epoch 4/100\n",
            "1979/2000 [============================>.] - ETA: 0s - loss: 0.5461 - accuracy: 0.8707\n",
            "Epoch 00004: val_accuracy did not improve from 0.85335\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5463 - accuracy: 0.8706 - val_loss: 0.6245 - val_accuracy: 0.8500\n",
            "Epoch 5/100\n",
            "1990/2000 [============================>.] - ETA: 0s - loss: 0.5475 - accuracy: 0.8719\n",
            "Epoch 00005: val_accuracy did not improve from 0.85335\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5477 - accuracy: 0.8719 - val_loss: 0.6241 - val_accuracy: 0.8490\n",
            "Epoch 6/100\n",
            "1987/2000 [============================>.] - ETA: 0s - loss: 0.5431 - accuracy: 0.8727\n",
            "Epoch 00006: val_accuracy did not improve from 0.85335\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5435 - accuracy: 0.8726 - val_loss: 0.6428 - val_accuracy: 0.8436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb2005526a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QTdjmOBpTgk",
        "outputId": "5cf81a6e-f9cd-4e08-9394-8fb88423ce66"
      },
      "source": [
        "model2.load_weights('best_weights.h5')\n",
        "model2.evaluate(X_test, y_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 1s 2ms/step - loss: 0.4903 - accuracy: 0.8533\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.490261971950531, 0.8533499836921692]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKbr1gRg9BXs"
      },
      "source": [
        "### Stretch Goals\n",
        "- Mount your Google Drive to Colab to persist your model checkpoint files. \n",
        "- Research L2 normalization (weight decay)\n",
        "- Write a custom callback function to stop training after you reach .88 validation accuracy. \n",
        "- Select a new dataset and apply a neural network to it.\n",
        "- Research TensorFlow Serving\n",
        "- Play [QuickDraw](https://quickdraw.withgoogle.com/data)\n",
        "- Create a static webpage using TensorFlow.js to serve a model. Check out [Teachable Machine Learning](https://teachablemachine.withgoogle.com/) for ideas. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cqpHQt_SIbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee52e817-f16a-4166-fe1b-0b72c407ed9f"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}